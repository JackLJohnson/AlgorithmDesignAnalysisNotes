\ifx\PREAMBLE\undefined
\input{preamble}
\begin{document}
\fi
\chapter{Data Structures}
Data structures help us organize data so that it can be accessed quickly and usefully. Different data structures support different sets of operations, thus are suitable for different tasks.
\section{Heap}
A heap, also named a priority queue, is a container for objects with comparable keys. It should support at least two basic operations: insertion of new object, and extraction(i.e. removal) of the object with minimum\footnote{A heap can also support extraction of object with maximum key, but extract-min and extract-max cannot be supported simultaneously.} key. Both operations are expected to take $O(\log n)$ time. Typical heap implementations also support deletion of an object from the key, which is also $O(\log n)$. The construction of a heap, namely ``heapify'', takes $O(n)$ rather than $O(n\log n)$.
\subsection{Use Cases}
Heap can be used for sorting. First construct a heap with the $n$ items to be sorted, and then execute extract-min $n$ times. The process takes $O(n\log n)$ time, which is already the optimal running time for comparison based sorting algorithms. 

We've already covered the use of a heap to accelerate Dijkstra's algorithm in the previous chapter.

An interesting use case of heap is median maintenance. We define the median of a sorted sequence of $n$ items $x_1,\dots,x_n$ to be $x_{(n+1)/2}$, for example $x_4$ for 8 items and $x_5$ for 9 items. 
\begin{description}
\item[Input]A sequence of unsorted items $x_1,x_2,\dots,x_n$ provided one-by-one.
\item[Output]At each step $i$, calculate the median of $x_1,\dots,x_i$ in $O(\log i)$ time.
\end{description}
The problem can be solved using two heaps, as shown in Algorithm \ref{medianmaintenance}. For convenience, we assume that the heaps used here supports not only the extraction of min/max, but also checking the key value of the min/max without removing it.
\begin{algorithm}[ht]
\caption{Median Maintenance using Heaps}\label{medianmaintenance}
\begin{algorithmic}[1]
\InputOutput\Statex{see above}
\State{Initialize empty MaxHeap that supports extract-max}\Comment{Stores smaller half}
\State{Initialize empty MinHeap that supports extract-min}\Comment{Stores larger half}
\For{$i$ = 1 \textbf{to} $n$}
\If{$x_i<$ MaxHeap.checkMax()}\Comment{Should insert into smaller half}
\State{MaxHeap.insert($x_i$)}
\Else\Comment{insert into larger half}
\State{MinHeap.insert($x_i$)}
\EndIf
\If{MinHeap.size() - MaxHeap.size() == 2}\Comment{If unbalanced, balance the two halves}
\State{MaxHeap.insert(MinHeap.extractMin()}
\ElsIf{MaxHeap.size() - MinHeap.size() == 2}
\State{MinHeap.insert(MaxHeap.extractMax()}
\EndIf
\If{MinHeap.size() $>$ MaxHeap.size()}\Comment{Set median}
\State{median = MinHeap.checkMin()}
\Else\State{median = MaxHeap.checkMax()}
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
\subsection{Implementation}
A heap can be conceptually thought of as a binary tree that is as complete as possible, i.e. null leaves are only allowed at the lowest level. The key of any node should be smaller than or equal to keys of its children, if there are any. This guarantees that the object at the root of the tree has the smallest key. This tree can be implemented as an array, with the root at the first position, and nodes at lower levels sequentially concatenated afterwards. If the array $A$ is 1-indexed, then the parent of $A[i]$ is $A[i/2]$, and the children of this node are $A[2i]$ and $A[2i+1]$.

With the array representation of heap, insertion can be implemented as follow:
\begin{itemize}
\item Put the new object at the end of the array.
\item As long as the key of the new object is smaller than that of its parent, bubble it up.
\end{itemize}
And extract-min can be implemented as follow:
\begin{itemize}
\item Remove the root.
\item Move the last object in the array to the first position.
\item As long as the key of the object at the root is larger than that of at least one of its children, sink it down. If the keys of both children are smaller, the child with smaller key should be used in the sink-down.
\end{itemize}
The height of the tree is $O(\log n)$, thus either bubble-up or sink-down can be executed at most $O(\log n)$ times, which guarantees that the two operations take $O(\log n)$ running time.
\section{Binary Search Tree}
Sorted array supports quick search of an element in $O(\log n)$ time, but it takes $O(n)$ time to insert or delete an element. Binary search tree is a data structure that supports both quick search and quick insertion / deletion. 
\subsection{Basic Operations}
Each node of a BST contains the key and three pointers to other nodes: the left child, the right child and the parent. Some of the three pointers can be null. The most important property of BST is that for any node, all nodes in its left child has smaller keys than itself, while all nodes in its right key has larger keys. The height of a BST is at least $\log n$ and at most $n$. A \textbf{balanced} BST supports search, insertion and deletion in $O(\log n)$ time. But if it's not balanced, these operations can take as long as $O(n)$ time. Some of its basic operations are listed below.
\begin{description}
\item[search]In order to search for a node with a specific key value $k$:
\begin{itemize}
\item Start from the root node.
\item If a node is null or its key is equal to $k$, return this node.
\item If $k$ is smaller than its key, recursively search its left child.
\item If $k$ is larger than its key, recursively search its right child.
\end{itemize}
\item[insert]In order to insert a new node with key value $k$:
\begin{itemize}
\item Start from the root node.
\item If the node is null, make a new node here with key value $k$.
\item If $k$ is smaller than its key, go to its left child.
\item If $k$ is larger than its key, go to its right child.
\end{itemize}
\item[max]In order to obtain the node with the maximum key value:
\begin{itemize}
\item Start from the root node.
\item If the node has right child, go to its right child.
\item Return the node.
\end{itemize}
\item[min]Similar to max.
\item[successor]In order to obtain the successor of a node with key value $k$:
\begin{itemize}
\item If the node has right child, return the max of its right node.
\item Otherwise recursively go to its parent, until the key becomes larger than $k$.
\end{itemize}
\item[predecessor]Similar to successor.
\item[in order traversal]In order to traverse all nodes of a BST in order:
\begin{itemize}
\item Start from the root node.
\item If the node is null, stop.
\item Recursively traverse the left child.
\item Do something to the node, e.g. print its key.
\item Recursively traverse the right child.
\end{itemize}
\item[delete]In order to delete a node with key value $k$:
\begin{itemize}
\item Search for the node.
\item If it has no child, change it to null.
\item If it has 1 child, replace it with its child.
\item If it has 2 children, find its predecessor, who is guaranteed to have at most 1 child, and swap their keys. Then delete the node (currently at its predecessor's old position).
\end{itemize}
\end{description}
Sometimes a tree node can contain some information about the tree itself, for example the size of the subtree that uses this node as root. For each node $n$, we have
$$size(n) = size(n.left) + size(n.right) + 1.$$
With this information, we can find the node with the $i^{th}$ largest key among all nodes:
\begin{itemize}
\item Start from the root node.
\item If $size(n.left) = i - 1$, return the node.
\item If $size(n.left) > i - 1$, return the node with the $i^{th}$ largest key in the left subtree.
\item If $size(n.left) < i - 1$, return the node with the $(i-size(n.left)-1)^{th}$ largest key in the right subtree.
\end{itemize}
\subsection{Red-Black Tree}
The height of a BST can vary between $O(\log n)$ and $O(n)$. Balanced BSTs are  guarantees to have $O(\log n)$ height, thus ensuring the efficiency of operations on it. Red-black trees is an implementation of balanced BST. In addition to the key and pointers to the parent and children, nodes in a red-black tree also stores a bit to indicate whether the node is red or black. The following conditions are satisfied by a red-black tree:
\begin{enumerate}
\item Each node is either red or black;
\item The root is black;\label{redblackcondition2}
\item There can never be two red nodes in a row, i.e. red nodes must have black parents and children;\label{redblackcondition3}
\item Every root $\rightarrow$ null path has the same number of black nodes.\label{redblackcondition4}
\end{enumerate}
\begin{theorem}
The height of a red-black tree with $n$ nodes is smaller than or equal to $O(2\log(n+1))$.
\end{theorem}
\begin{proof}
Suppose all root $\rightarrow$ null paths contain $k$ black nodes. Then the red-black contains at lest $k$ complete levels, because otherwise there would exist root $\rightarrow$ null paths with fewer than $k$ nodes, thus of cause fewer than $k$ black nodes. Therefore we have 
$$n\geq 1 + 2 + \dots + 2^{k-1} = 2^k-1,$$
which means $k\leq\log(n+1).$ Suppose the height of the tree is $h$. According to condition \ref{redblackcondition3}, we hereby come to the conclusion 
$$h\leq 2k\leq 2\log(n+1).$$
\end{proof}
An important idea in the implementation of red-black tree is rotation, as illustrated in Figure \ref{rotations}. It alters the structure of the tree in a way that makes the tree more balanced, whilst preserves the BST property.

\begin{figure}[ht]
\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}
\tikzstyle{subtree} = [regular polygon, regular polygon sides = 4, draw]
\tikzstyle{singlenode} = [circle,draw]
\node[circle, draw](1) at (0,0){1}
child { node[subtree] {A} }
child  { node [singlenode] {2}
	child { node[subtree] {B} }
	child { node[subtree] {C} }
};
\node[circle, draw](2)[right= 5cm of 1]{2}
child  { node [singlenode] {1}
	child { node[subtree] {A} }
	child { node[subtree] {B} }
}
child { node[subtree] {C} };
\draw[->,very thick] (2.3,-1.5) -- (3.3,-1.5); 
\end{tikzpicture}
\caption{left rotation}
\end{subfigure}\\
\begin{subfigure}{\textwidth}
\centering
\begin{tikzpicture}
\tikzstyle{subtree} = [regular polygon, regular polygon sides = 4, draw]
\tikzstyle{singlenode} = [circle,draw]
\node[singlenode](1) at (0,0){1}
child  { node [singlenode] {2}
	child { node[subtree] {A} }
	child { node[subtree] {B} }
}
child { node[subtree] {C} };
\node[singlenode](2)[right= 3cm of 1]{2}
child { node[subtree] {A} }
child  { node [singlenode] {1}
	child { node[subtree] {B} }
	child { node[subtree] {C} }
};
\draw[->,very thick] (1.3,-1.5) -- (2.3,-1.5); 
\end{tikzpicture}
\caption{right rotation}
\end{subfigure}
\caption{Rotations in Red Black Tree}\label{rotations}
\end{figure}

Insertion and deletion in a red-black tree is carried out in two steps. First a normal BST insertion / BST is executed. It is probable that some of the conditions of red-black tree will be violated, thus we then modify the tree by recoloring the nodes and rotations in order to restore the conditions.

When we insert a node into the red-black tree as we do for any BST, we first try to color it as red. If condition \ref{redblackcondition3} is not violated, then everything is fine. Otherwise we wind up in two possible cases, as shown in Figure \ref{redblackinsertion}, in which $x$ is the newly inserted node. 

In case 1, all we need to do is a recoloring of the nodes. The red node is propagated upwards, which may possibly induce another violation of \ref{redblackcondition3}. The process can last as much as $O(\log n)$ times until we reach the root. If the root is colored red, condition \ref{redblackcondition2} will be violated, and the solution is to color it back to black. 

During the upward propagation process, it is possible that we meet case 2. Tackling this case is a little bit more complex, but it can be proven that the conditions can be restored via 2-3 rotations and recolorings in $O(1)$ time.

\begin{figure}[H]
\begin{subfigure}{.6\textwidth}
\centering
\begin{tikzpicture}
\tikzstyle{rednode}=[circle,draw,red]
\tikzstyle{blacknode}=[circle,draw]
\node[blacknode](w) at (0,0) {w}
child {node[rednode]{z}}
child {node[rednode]{y}
	child{node[rednode,left]{x}}
};
\node[rednode](w1) [right = 3cm of w] {w}
child {node[blacknode]{z}}
child {node[blacknode]{y}
	child{node[rednode,left]{x}}
};
\draw[->,very thick] (1.3,-1.5) -- (2.3,-1.5);
\end{tikzpicture}
\caption{case 1}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
\centering
\begin{tikzpicture}
\tikzstyle{rednode}=[circle,draw,red]
\tikzstyle{blacknode}=[circle,draw]
\tikzstyle{subtree} = [regular polygon, regular polygon sides = 4, draw]
\node[blacknode](w2) {w}
child {node[blacknode]{z}}
child {node[rednode]{y}
	child{node[rednode]{x}
		child{node[subtree]{...}}
		child{node[subtree]{...}}
	}
	child{node[subtree]{...}}
};
\end{tikzpicture}
\caption{case 2}
\end{subfigure}
\caption{Insertion in a Red-Black Tree}\label{redblackinsertion}
\end{figure}
\section{Hash Table}
\ifx\PREAMBLE\undefined
\end{document}
\fi