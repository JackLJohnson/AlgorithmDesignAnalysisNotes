\ifx\PREAMBLE\undefined
\input{preamble}
\begin{document}
\fi
\chapter{Data Structures}
Data structures help us organize data so that it can be accessed quickly and usefully. Different data structures support different sets of operations, thus are suitable for different tasks.
\section{Heap}
A heap, also named a priority queue, is a container for objects with comparable keys. It should support at least two basic operations: insertion of new object, and extraction(i.e. removal) of the object with minimum\footnote{A heap can also support extraction of object with maximum key, but extract-min and extract-max cannot be supported simultaneously.} key. Both operations are expected to take $O(\log n)$ time. Typical heap implementations also support deletion of an object from the key, which is also $O(\log n)$. The construction of a heap, namely ``heapify'', takes $O(n)$ rather than $O(n\log n)$.
\subsection{Use Cases}
Heap can be used for sorting. First construct a heap with the $n$ items to be sorted, and then execute extract-min $n$ times. The process takes $O(n\log n)$ time, which is already the optimal running time for comparison based sorting algorithms. 

We've already covered the use of a heap to accelerate Dijkstra's algorithm in the previous chapter.

An interesting use case of heap is median maintenance. We define the median of a sorted sequence of $n$ items $x_1,\dots,x_n$ to be $x_{(n+1)/2}$, for example $x_4$ for 8 items and $x_5$ for 9 items. 
\begin{description}
\item[Input]A sequence of unsorted items $x_1,x_2,\dots,x_n$ provided one-by-one.
\item[Output]At each step $i$, calculate the median of $x_1,\dots,x_i$ in $O(\log i)$ time.
\end{description}
The problem can be solved using two heaps, as shown in Algorithm \ref{medianmaintenance}. For convenience, we assume that the heaps used here supports not only the extraction of min/max, but also checking the key value of the min/max without removing it.
\begin{algorithm}[ht]
\caption{Median Maintenance using Heaps}\label{medianmaintenance}
\begin{algorithmic}[1]
\InputOutput\Statex{see above}
\State{Initialize empty MaxHeap that supports extract-max}\Comment{Stores smaller half}
\State{Initialize empty MinHeap that supports extract-min}\Comment{Stores larger half}
\For{$i$ = 1 \textbf{to} $n$}
\If{$x_i<$ MaxHeap.checkMax()}\Comment{Should insert into smaller half}
\State{MaxHeap.insert($x_i$)}
\Else\Comment{insert into larger half}
\State{MinHeap.insert($x_i$)}
\EndIf
\If{MinHeap.size() - MaxHeap.size() == 2}\Comment{If unbalanced, balance the two halves}
\State{MaxHeap.insert(MinHeap.extractMin()}
\ElsIf{MaxHeap.size() - MinHeap.size() == 2}
\State{MinHeap.insert(MaxHeap.extractMax()}
\EndIf
\If{MinHeap.size() $>$ MaxHeap.size()}\Comment{Set median}
\State{median = MinHeap.checkMin()}
\Else\State{median = MaxHeap.checkMax()}
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}
\subsection{Implementation}
A heap can be conceptually thought of as a binary tree that is as complete as possible, i.e. null leaves are only allowed at the lowest level. The key of any node should be smaller than or equal to keys of its children, if there are any. This guarantees that the object at the root of the tree has the smallest key. This tree can be implemented as an array, with the root at the first position, and nodes at lower levels sequentially concatenated afterwards. If the array $A$ is 1-indexed, then the parent of $A[i]$ is $A[i/2]$, and the children of this node are $A[2i]$ and $A[2i+1]$.

With the array representation of heap, insertion can be implemented as follow:
\begin{itemize}
\item Put the new object at the end of the array.
\item As long as the key of the new object is smaller than that of its parent, bubble it up.
\end{itemize}
And extract-min can be implemented as follow:
\begin{itemize}
\item Remove the root.
\item Move the last object in the array to the first position.
\item As long as the key of the object at the root is larger than that of at least one of its children, sink it down. If the keys of both children are smaller, the child with smaller key should be used in the sink-down.
\end{itemize}
The height of the tree is $O(\log n)$, thus either bubble-up or sink-down can be executed at most $O(\log n)$ times, which guarantees that the two operations take $O(\log n)$ running time.
\section{Binary Search Tree}
Sorted array supports quick search of an element in $O(\log n)$ time, but it takes $O(n)$ time to insert or delete an element. Binary search tree is a data structure that supports both quick search and quick insertion / deletion. 
\subsection{Basic Operations}
Each node of a BST contains the key and three pointers to other nodes: the left child, the right child and the parent. Some of the three pointers can be null. The most important property of BST is that for any node, all nodes in its left child has smaller keys than itself, while all nodes in its right key has larger keys. The height of a BST is at least $\log n$ and at most $n$. A \textbf{balanced} BST supports search, insertion and deletion in $O(\log n)$ time. But if it's not balanced, these operations can take as long as $O(n)$ time. Some of its basic operations are listed below.
\begin{description}
\item[search]In order to search for a node with a specific key value $k$:
\begin{itemize}
\item Start from the root node.
\item If a node is null or its key is equal to $k$, return this node.
\item If $k$ is smaller than its key, recursively search its left child.
\item If $k$ is larger than its key, recursively search its right child.
\end{itemize}
\item[insert]In order to insert a new node with key value $k$:
\begin{itemize}
\item Start from the root node.
\item If the node is null, make a new node here with key value $k$.
\item If $k$ is smaller than its key, go to its left child.
\item If $k$ is larger than its key, go to its right child.
\end{itemize}
\item[max]In order to obtain the node with the maximum key value:
\begin{itemize}
\item Start from the root node.
\item If the node has right child, go to its right child.
\item Return the node.
\end{itemize}
\item[min]Similar to max.
\item[successor]In order to obtain the successor of a node with key value $k$:
\begin{itemize}
\item If the node has right child, return the max of its right node.
\item Otherwise recursively go to its parent, until the key becomes larger than $k$.
\end{itemize}
\item[predecessor]Similar to successor.
\item[in order traversal]In order to traverse all nodes of a BST in order:
\begin{itemize}
\item Start from the root node.
\item If the node is null, stop.
\item Recursively traverse the left child.
\item Do something to the node, e.g. print its key.
\item Recursively traverse the right child.
\end{itemize}
\item[delete]In order to delete a node with key value $k$:
\begin{itemize}
\item Search for the node.
\item If it has no child, change it to null.
\item If it has 1 child, replace it with its child.
\item If it has 2 children, find its predecessor, who is guaranteed to have at most 1 child, and swap their keys. Then delete the node (currently at its predecessor's old position).
\end{itemize}
\end{description}
Sometimes a tree node can contain some information about the tree itself, for example the size of the subtree that uses this node as root. For each node $n$, we have
$$size(n) = size(n.left) + size(n.right) + 1.$$
With this information, we can find the node with the $i^{th}$ largest key among all nodes:
\begin{itemize}
\item Start from the root node.
\item If $size(n.left) = i - 1$, return the node.
\item If $size(n.left) > i - 1$, return the node with the $i^{th}$ largest key in the left subtree.
\item If $size(n.left) < i - 1$, return the node with the $(i-size(n.left)-1)^{th}$ largest key in the right subtree.
\end{itemize}
\subsection{Red Black Tree}
\ifx\PREAMBLE\undefined
\end{document}
\fi